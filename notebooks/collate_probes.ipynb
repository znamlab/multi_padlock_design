{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in all csvs that begin with \"6.Probes\" and end with \".csv\"\n",
    "# set the directory where the subdirectories are located\n",
    "parent_dir = \"/nemo/lab/znamenskiyp/scratch/Olfr_genes\"\n",
    "\n",
    "# create an empty list to hold the csv files\n",
    "csv_files = []\n",
    "\n",
    "for subdir in [d for d in os.listdir(parent_dir) if d.startswith(\"Olfr\")]:\n",
    "    subpath = os.path.join(parent_dir, subdir)\n",
    "    if os.path.isdir(subpath) and glob.glob(\n",
    "        os.path.join(subpath, \"6.ProbesRandom*.csv\")\n",
    "    ):\n",
    "        csv_files.append(glob.glob(os.path.join(subpath, \"6.ProbesRandom*.csv\"))[0])\n",
    "\n",
    "\n",
    "# Robust parser handling variable delimiter and extra transcript_region columns\n",
    "def read_probe_csv(path):\n",
    "    records = []\n",
    "    with open(path, \"r\") as fh:\n",
    "        header = next(fh, None)  # skip header line\n",
    "        for raw in fh:\n",
    "            raw = raw.rstrip(\"\\r\\n\")\n",
    "            if not raw.strip():\n",
    "                continue\n",
    "            # Decide delimiter: prefer tab, else comma if many commas, else whitespace\n",
    "            if \"\\t\" in raw:\n",
    "                parts = raw.split(\"\\t\")\n",
    "            else:\n",
    "                if raw.count(\",\") >= 6:\n",
    "                    parts = raw.split(\",\")\n",
    "                else:\n",
    "                    parts = re.split(r\"\\s+\", raw)\n",
    "            # Ensure at least 6 fixed columns (pad if short)\n",
    "            if len(parts) < 6:\n",
    "                parts += [\"\"] * (6 - len(parts))\n",
    "            fixed = parts[:6]\n",
    "            extra_parts = parts[6:]  # transcript_region (possibly split)\n",
    "            # Drop pure empty trailing tokens\n",
    "            extra_parts = [p for p in extra_parts if p != \"\"]\n",
    "            region_raw = \" \".join(extra_parts).strip()\n",
    "            tokens = []\n",
    "            if region_raw:\n",
    "                # Remove brackets\n",
    "                region_clean = region_raw.replace(\"[\", \" \").replace(\"]\", \" \")\n",
    "                # Remove quotes\n",
    "                region_clean = region_clean.replace(\"'\", \"\").replace('\"', \"\")\n",
    "                # Split on commas or whitespace\n",
    "                for t in re.split(r\"[\\s,]+\", region_clean):\n",
    "                    if t:\n",
    "                        tokens.append(t)\n",
    "            records.append(fixed + [tokens])\n",
    "    cols = [\n",
    "        \"acronym\",\n",
    "        \"target\",\n",
    "        \"Tm\",\n",
    "        \"startpos\",\n",
    "        \"endpos\",\n",
    "        \"padlock\",\n",
    "        \"transcript_region\",\n",
    "    ]\n",
    "    df_local = pd.DataFrame(records, columns=cols)\n",
    "    # Per-file gene_name extraction: find row whose acronym starts with '>'\n",
    "    if not df_local.empty:\n",
    "        header_mask = df_local[\"acronym\"].astype(str).str.startswith(\">\")\n",
    "        if header_mask.any():\n",
    "            gene_name = df_local.loc[header_mask, \"acronym\"].iloc[0][1:]\n",
    "            df_local = df_local.loc[~header_mask].copy()  # drop header row(s)\n",
    "            df_local[\"gene_name\"] = gene_name\n",
    "        else:\n",
    "            # Fallback: strip any leading '>' just in case\n",
    "            df_local[\"gene_name\"] = df_local[\"acronym\"].astype(str).str.lstrip(\">\")\n",
    "    return df_local\n",
    "\n",
    "\n",
    "# Read and concatenate (each df already contains gene_name, header rows removed)\n",
    "dfs = [read_probe_csv(f) for f in csv_files]\n",
    "df = (\n",
    "    pd.concat(dfs, ignore_index=True)\n",
    "    if dfs\n",
    "    else pd.DataFrame(\n",
    "        columns=[\n",
    "            \"acronym\",\n",
    "            \"target\",\n",
    "            \"Tm\",\n",
    "            \"startpos\",\n",
    "            \"endpos\",\n",
    "            \"padlock\",\n",
    "            \"transcript_region\",\n",
    "            \"gene_name\",\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Drop rows missing required probe fields\n",
    "df = df.dropna(subset=[\"target\", \"padlock\"])\n",
    "\n",
    "\n",
    "def remove_chars(s, indices):\n",
    "    for i in sorted(indices, reverse=True):\n",
    "        s = s[:i] + s[i + 1 :]\n",
    "    return s\n",
    "\n",
    "\n",
    "df.to_csv(\"Olfr_monahan_probes.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iss-preprocess",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
